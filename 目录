前言

1 简介

2 统计学习
2.1 什么是统计学习
2.1.1 为什么要估计F？
2.1.2 我们怎样估计F？
2.1.3 预测准确性与模型可解释性间的取舍
2.1.4 监督学习与非监督学习
2.1.5 回归问题与分类问题
2.2 评估模型准确性
2.2.1 测量拟合度
2.2.2 偏差-方差的取舍
2.2.3 分类的设置
2.3 实验：R的简介
2.3.1 基础命令
2.3.2 绘图
2.3.3 数据索引
2.3.4 数据加载
2.3.5 高级绘图与数字总结方法
2.4 练习

3 线性回归
3.1 简单线性回归
3.1.1 估计系数
3.1.2 评估系数估计的准确性
3.1.3 评估模型的准确性
3.2 多元线性回归
3.2.1 估计回归系数
3.2.2 一些重要问题
3.3 回归模型中其他需要考虑的问题
3.3.1 定性的预测变量
3.3.2 线性模型的可扩展性
3.3.3 潜在问题
3.4 市场计划
3.5 线性回归与KNN（K最邻近）的比较
3.6 实验：线性回归
3.6.1 R包
3.6.2 简单线性回归
3.6.3 多元线性回归
3.6.4 交互作用项
3.6.5 非线性预测变量的转换
3.6.6 定性变量
3.6.7 编写函数
3.7 练习

4 分类
4.1 分类概述
4.2 为什么不用线性回归
4.3 逻辑回归
4.3.1 逻辑模型
4.3.2 估计回归系数
4.3.3 作出预测
4.3.4 多元逻辑回归
4.3.5 多分类问题（分类大于2）的逻辑回归
4.4 线性判别分析（LDA）
4.4.1 用贝叶斯理论进行分类
4.4.2 p=1时的线性判别分析
4.4.3 p>1时的线性判别分析
4.4.4 二次判别分析（QDA）
4.5 分类方法的比较
4.6 实验：逻辑回归，LDA，QDA和KNN
4.6.1 股票市场数据
4.6.2 逻辑回归
4.6.3 线性判别分析
4.6.4 二次判别分析
4.6.5 K最邻近法
4.6.6 Caravan保险数据应用
4.7 练习

5 重采样方法
5.1 交叉验证
5.1.1 校验集方法
5.1.2 留一验证（LOOCV）
5.1.3 k折交叉验证
5.1.4 k折交叉验证的偏差-方差取舍
5.1.5 分类问题中的交叉验证
5.2 自举算法
5.3 实验：交叉验证和自举
5.3.1 校验集方法
5.3.2 留一验证
5.3.3 k折交叉验证
5.3.4 自举
5.4 练习

6 线性模型的筛选和正则化
6.1 子集筛选
6.1.1 最优子集筛选
6.1.2 逐步筛选法
6.1.3 最优模型的选择
6.2 收缩方法（正则化）
6.2.1 岭回归
6.2.2 套索
6.2.3 筛选调节参数
6.3 降维方法
6.3.1 主成分回归
6.3.2 部分最小二乘法
6.4 高维问题注意事项
6.4.1 高维数据
6.4.2 高维数据存在的问题
6.4.3 高维数据的回归
6.4.4 高维数据的可解释性结果
6.5 实验1：子集筛选方法
6.5.1 最优子集筛选
6.5.2 向前和向后逐步筛选法
6.5.3 使用校验集方法和交叉验证法选择模型
6.6 实验2：岭回归和套索
6.6.1 岭回归
6.6.2 套索
6.7 实验3：PCR和PLS回归
6.7.1 主成分回归
6.7.2 部分最小二乘法
6.8 练习

7 超越线性
7.1 多项式回归
7.2 阶跃函数
7.3 基础函数
7.4 样条回归
7.4.1 分段多项式
7.4.2 约束和样条
7.4.3 样条基础表达
7.4.4 选择节点的数量和位置
7.4.5 与多项式回归的比较
7.5 光滑样条
7.5.1 光滑样条概述
7.5.2 选择光滑参数λ
7.6 局部回归
7.7 广义加性模型（GAMs）
7.7.1 回归问题的GAMs
7.7.2 分类问题的GAMs
7.8 实验：非线性建模
7.8.1 多项式回归和阶跃函数
7.8.2 样条
7.8.3 GAMs
7.9 练习

8 基于树的方法
8.1 决策树基础
8.1.1 回归树
8.1.2 分类树
8.1.3 树与线性模型
8.1.4 树的优缺点
8.2 装袋（bagging），随机森林，提升（Boosting）
8.2.1 装袋（bagging）
8.2.2 随机森林
8.2.3 提升（Boosting）
8.3 实验：决策树
8.3.1 拟合分类树
8.3.2 拟合回归树
8.3.3 装袋（bagging）与随机森林
8.3.4 提升（Boosting）
8.4 练习

9 支持向量机
9.1 最大间隔分类器
9.1.1 什么是超平面
9.1.2 使用分离超平面进行分类
9.1.3 最大间隔分类器
9.1.4 最大间隔分类器的结构
9.1.5 非分离案例
9.2 支持向量分类器
9.2.1 支持向量分类器概述
9.2.2 支持向量分类器详情
9.3 支持向量机
9.3.1 使用非线性决策边界分类
9.3.2 支持向量机
9.3.3 在心脏疾病数据中的应用
9.4 多分类SVMs
9.4.1 一对一分类
9.4.2 一对多分类
9.5 与逻辑回归间的关系
9.6 实验：支持向量机
9.6.1 支持向量分类器
9.6.2 支持向量机
9.6.3 ROC曲线
9.6.4 SVM与多分类
9.6.5 在基因表达数据中的应用
9.7 练习

10 非监督学习
10.1 非监督学习的挑战
10.2 主成分分析
10.2.1 什么是主成分
10.2.2 主成分的其他理解
10.2.3 PCA的更多内容
10.2.4 主成分的其他用途
10.3 聚类方法
10.3.1 K均值聚类
10.3.2 层次聚类
10.3.3 聚类的实际问题
10.4 实验1：主成分分析
10.5 实验2：聚类
10.5.1 K均值聚类
10.5.2 层次聚类
10.6 实验3：NCI60数据案例
10.6.1 使用PCA处理NCI60数据
10.6.2 NCI60数据的观察样本聚类
10.7 练习

索引
